# Sistema NLP para ProgramaciÃ³n Lineal

## DescripciÃ³n

Este sistema integra capacidades de Procesamiento de Lenguaje Natural (NLP) con el solver Simplex existente, permitiendo resolver problemas de optimizaciÃ³n descritos en lenguaje natural.

## Arquitectura

El sistema sigue los principios SOLID y utiliza patrones de diseÃ±o para mantener bajo acoplamiento:

### Estructura del Proyecto

El sistema NLP estÃ¡ completamente organizado en `src/nlp/`:

```
src/
â”œâ”€â”€ nlp/                    # ðŸ†• Carpeta dedicada al sistema NLP
â”‚   â”œâ”€â”€ __init__.py        # Exporta todas las clases pÃºblicas
â”‚   â”œâ”€â”€ interfaces.py      # Interfaces y abstracciones SOLID
â”‚   â”œâ”€â”€ config.py          # ConfiguraciÃ³n de modelos y constantes
â”‚   â”œâ”€â”€ processor.py       # Procesadores NLP (Transformer, Mock)
â”‚   â”œâ”€â”€ model_generator.py # Generadores de modelos (Simplex, PuLP, OR-Tools)
â”‚   â””â”€â”€ connector.py       # Conectores y orchestradores
â”œâ”€â”€ solver.py              # Solver Simplex original (sin modificar)
â””â”€â”€ ...
```

### Componentes Principales

1. **INLPProcessor** (`nlp/interfaces.py`): Interfaz para procesadores de lenguaje natural

   - `TransformerNLPProcessor` (`nlp/processor.py`): FLAN-T5, Mistral, etc.
   - `MockNLPProcessor` (`nlp/processor.py`): ImplementaciÃ³n mock para testing

2. **IModelGenerator** (`nlp/interfaces.py`): Interfaz para generadores de modelos

   - `SimplexModelGenerator` (`nlp/model_generator.py`): Formato SimplexSolver
   - `PuLPModelGenerator` (`nlp/model_generator.py`): Formato PuLP (opcional)
   - `ORToolsModelGenerator` (`nlp/model_generator.py`): Formato OR-Tools (opcional)

3. **IOptimizationSolver** (`nlp/interfaces.py`): Interfaz para solvers

   - `SimplexSolverAdapter` (`nlp/connector.py`): Adapta el SimplexSolver existente

4. **INLPConnector** (`nlp/interfaces.py`): Interfaz para conectores del pipeline completo

   - `NLPOptimizationConnector` (`nlp/connector.py`): Orquesta todo el proceso

5. **IModelValidator** (`nlp/interfaces.py`): Valida problemas extraÃ­dos por NLP
   - `ModelValidator` (`nlp/model_generator.py`): ValidaciÃ³n de problemas

### Principios SOLID Aplicados

- **SRP**: Cada clase tiene una Ãºnica responsabilidad
- **OCP**: Extensible sin modificar cÃ³digo existente
- **LSP**: Implementaciones intercambiables mediante interfaces
- **ISP**: Interfaces especÃ­ficas y cohesivas
- **DIP**: Dependencia de abstracciones, no concreciones

## InstalaciÃ³n

1. Instalar dependencias:

```bash
pip install -r requirements.txt
```

2. Para usar modelos locales, asegurar que tenga suficiente RAM y espacio en disco:
   - FLAN-T5-small: ~1GB RAM
   - FLAN-T5-base: ~3GB RAM
   - Mistral-7B: ~14GB RAM (con quantizaciÃ³n 4-bit: ~4GB)

## Uso

### Modo NLP con texto directo

```bash
python nlp_simplex.py --nlp --text "Maximizar 3x + 2y sujeto a x + y <= 4 y 2x + y <= 6"
```

### Modo NLP con archivo

```bash
python nlp_simplex.py --nlp --file ejemplos/nlp/problema_produccion_simple.txt
```

### Modo NLP interactivo

```bash
python nlp_simplex.py --nlp
```

### Usar modelo especÃ­fico

```bash
python nlp_simplex.py --nlp --model t5-base --text "..."
```

### Modo de prueba (mock NLP)

```bash
python nlp_simplex.py --nlp --mock --text "cualquier texto"
```

### Modo tradicional (sin cambios)

```bash
python nlp_simplex.py ejemplos/maximizar_basico.txt
```

## Ejemplos de Problemas NLP

### Problema de ProducciÃ³n

```
Una empresa produce dos productos A y B.
A genera 3 unidades de ganancia, B genera 2 unidades.
Maximizar ganancias sujeto a:
- A + B <= 4 (capacidad)
- 2A + B <= 6 (recursos)
```

### Problema de Transporte

```
Minimizar costos de envÃ­o en 3 rutas.
Ruta 1 cuesta 5 por unidad, ruta 2 cuesta 3, ruta 3 cuesta 4.
Restricciones:
- Enviar al menos 10 unidades total
- Ruta 1 mÃ¡ximo 8 unidades
- Ruta 2 mÃ¡ximo 6 unidades
```

## API ProgramÃ¡tica

### Uso BÃ¡sico

```python
# ðŸ†• ImportaciÃ³n simplificada desde el paquete nlp
from nlp import NLPConnectorFactory, SolverType, NLPModelType

# Crear conector
connector = NLPConnectorFactory.create_connector(
    nlp_model_type=NLPModelType.FLAN_T5_SMALL,
    solver_type=SolverType.SIMPLEX,
    use_mock_nlp=False  # True para testing
)

# Procesar problema
result = connector.process_and_solve(
    "Maximizar 2x + 3y sujeto a x + y <= 10"
)

if result['success']:
    print("SoluciÃ³n:", result['solution'])
else:
    print("Error:", result['error'])
```

### Uso Avanzado con ConfiguraciÃ³n

```python
# ðŸ†• ImportaciÃ³n simplificada
from nlp import ConfigurableNLPConnector, NLPModelType, SolverType

connector = ConfigurableNLPConnector()

# Configurar conector
success = connector.configure(
    nlp_model_type=NLPModelType.MISTRAL_7B,
    solver_type=SolverType.SIMPLEX,
    use_mock_nlp=False,
    custom_config={
        'temperature': 0.5,
        'max_length': 1024
    }
)

if success:
    result = connector.process_and_solve(problem_text)
```

## Testing

Ejecutar tests:

```bash
python -m pytest tests/ -v
```

O ejecutar directamente:

```bash
python tests/test_nlp_system.py
```

## Arquitectura de Microservicio

El sistema estÃ¡ diseÃ±ado como si fuera un microservicio:

1. **Bajo Acoplamiento**: Componentes intercambiables vÃ­a interfaces
2. **Alta CohesiÃ³n**: Cada componente tiene responsabilidad especÃ­fica
3. **Conector Adaptable**: FÃ¡cil cambio de lÃ³gica principal o NLP
4. **ConfiguraciÃ³n Flexible**: MÃºltiples modelos y configuraciones
5. **Monitoreo**: Health checks y logging detallado

### Cambiar Componentes

Para cambiar el procesador NLP:

```python
# Implementar nueva clase
class CustomNLPProcessor(INLPProcessor):
    def process_text(self, text: str) -> NLPResult:
        # LÃ³gica personalizada
        pass

# Usar en conector
connector = NLPOptimizationConnector(
    nlp_processor=CustomNLPProcessor(),
    model_generator=SimplexModelGenerator(),
    solver=SimplexSolverAdapter(),
    validator=ModelValidator()
)
```

Para cambiar el solver:

```python
class CustomSolver(IOptimizationSolver):
    def solve(self, model: Dict[str, Any]) -> Dict[str, Any]:
        # LÃ³gica de solver personalizada
        pass
```

## Modelos NLP Soportados

### FLAN-T5 (Recomendado para empezar)

- **t5-small**: RÃ¡pido, menor precisiÃ³n, ~1GB RAM
- **t5-base**: Balance velocidad/precisiÃ³n, ~3GB RAM

### Mistral 7B (Mayor calidad)

- Mejor comprensiÃ³n de lenguaje natural
- Requiere ~4GB RAM con quantizaciÃ³n
- MÃ¡s lento pero mÃ¡s preciso

### Extensiones Futuras

- Support para LLaMA 2
- Modelos fine-tuneados especÃ­ficos para optimizaciÃ³n
- Cache de resultados NLP
- Procesamiento batch

## Troubleshooting

### Error: "transformers library not available"

```bash
pip install torch transformers accelerate
```

### Error: "CUDA not available"

- Normal si no tiene GPU NVIDIA
- El sistema automÃ¡ticamente usa CPU
- Para GPU: instalar `torch` con soporte CUDA

### Error: "Model not loading"

- Verificar memoria disponible
- Usar modelo mÃ¡s pequeÃ±o (t5-small)
- Activar modo mock: `--mock-nlp`

### Error de memoria con modelos grandes

```python
# Usar quantizaciÃ³n
custom_config = {
    'load_in_4bit': True,  # Reduce memoria
    'device_map': 'auto'
}
```

## Logging

El sistema incluye logging detallado:

```bash
# Modo verboso
python nlp_simplex.py --nlp --verbose --text "..."

# En cÃ³digo
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ContribuciÃ³n

Para agregar nuevos componentes:

1. Implementar interfaces correspondientes
2. Agregar tests unitarios
3. Documentar configuraciÃ³n
4. Actualizar factory si necesario

El diseÃ±o modular facilita extensiones sin modificar cÃ³digo existente.
