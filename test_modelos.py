"""
Test autom√°tico de modelos NLP para resolver el problema complejo.

Este script prueba diferentes modelos en orden de eficiencia hasta encontrar
uno que resuelva correctamente el problema de las 3 plantas.
"""

import sys
import logging
from pathlib import Path
import time

# Agregar src al path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from nlp import (
    TransformerNLPProcessor,
    NLPModelType,
    ModelSelector,
)


# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)


def test_model(model_type: NLPModelType, problem_text: str, timeout: int = 600) -> bool:
    """
    Prueba un modelo espec√≠fico con el problema.

    Returns:
        True si el modelo resolvi√≥ el problema correctamente, False si no.
    """
    logger.info("=" * 70)
    logger.info(f"üß™ Probando modelo: {model_type.value}")
    logger.info("=" * 70)

    try:
        start_time = time.time()

        # Crear procesador con el modelo espec√≠fico
        processor = TransformerNLPProcessor(
            model_type=model_type,
            auto_select_model=False,  # Desactivar selecci√≥n autom√°tica
        )

        # Procesar el problema
        logger.info("üìù Procesando problema...")
        result = processor.process_text(problem_text)

        elapsed_time = time.time() - start_time

        # Verificar resultado
        if result.success:
            logger.info(f"‚úÖ √âXITO! Modelo {model_type.value} resolvi√≥ el problema")
            logger.info(f"‚è±Ô∏è  Tiempo: {elapsed_time:.1f} segundos")
            logger.info(f"üìä Confianza: {result.confidence_score:.2%}")

            if result.problem:
                logger.info(
                    f"üìà Variables: {len(result.problem.objective_coefficients)}"
                )
                logger.info(f"üìã Restricciones: {len(result.problem.constraints)}")
                logger.info(f"üéØ Objetivo: {result.problem.objective_type}")

            return True
        else:
            logger.warning(f"‚ùå Fall√≥: {result.error_message}")
            logger.info(f"‚è±Ô∏è  Tiempo hasta fallo: {elapsed_time:.1f} segundos")
            return False

    except KeyboardInterrupt:
        logger.warning("‚ö†Ô∏è  Test interrumpido por el usuario")
        raise
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        return False


def main():
    """Ejecuta tests con diferentes modelos en orden de prioridad."""

    print("\n" + "=" * 70)
    print("üî¨ TEST AUTOM√ÅTICO DE MODELOS NLP")
    print("=" * 70)

    # Cargar problema
    problem_file = Path("ejemplos/nlp/problema_complejo.txt")
    if not problem_file.exists():
        logger.error(f"‚ùå No se encontr√≥ el archivo: {problem_file}")
        return

    problem_text = problem_file.read_text(encoding="utf-8")
    logger.info(f"\nüìÑ Problema cargado: {len(problem_text)} caracteres\n")

    # Mostrar an√°lisis autom√°tico primero
    logger.info("üîç An√°lisis autom√°tico del problema:")
    selector = ModelSelector()
    recommended_model = selector.select_model(problem_text)
    logger.info(f"   Modelo recomendado: {recommended_model.value}\n")

    # Lista de modelos a probar en orden de eficiencia
    # (primero los m√°s r√°pidos/peque√±os, luego los m√°s potentes)
    models_to_test = [
        # Modelos peque√±os pero potentes (recomendados)
        NLPModelType.PHI_3_MINI,  # 3.8GB, muy preciso, funciona en CPU
        NLPModelType.GEMMA_2B,  # 2GB, r√°pido, buena precisi√≥n
        # Si los anteriores fallan, probar con los grandes
        NLPModelType.GEMMA_7B,  # 7GB, muy preciso
        NLPModelType.FLAN_T5_LARGE,  # 780MB, como √∫ltimo recurso ligero
        # Nota: Mistral y Llama3 requieren GPU, los dejamos comentados
        # NLPModelType.MISTRAL_7B,    # Requiere GPU
        # NLPModelType.LLAMA3_8B,     # Requiere GPU
    ]

    print("\nüìã Modelos a probar (en orden):")
    for i, model in enumerate(models_to_test, 1):
        print(f"   {i}. {model.value}")
    print()

    # Probar cada modelo
    for i, model_type in enumerate(models_to_test, 1):
        logger.info(f"\n{'='*70}")
        logger.info(f"Test {i}/{len(models_to_test)}")
        logger.info(f"{'='*70}\n")

        try:
            success = test_model(model_type, problem_text)

            if success:
                print("\n" + "=" * 70)
                print("üéâ ¬°PROBLEMA RESUELTO!")
                print("=" * 70)
                print(f"\n‚úÖ Modelo exitoso: {model_type.value}")
                print("\nüí° Puedes usar este modelo en el futuro especificando:")
                print(
                    f"   python nlp_simplex.py --nlp --model {model_type.name.lower()} --file problema.txt"
                )
                print()
                return

        except KeyboardInterrupt:
            logger.warning("\n‚ö†Ô∏è  Tests interrumpidos por el usuario")
            return
        except Exception as e:
            logger.error(f"Error inesperado: {e}")
            continue

        # Pausa entre tests
        if i < len(models_to_test):
            logger.info("\n‚è≥ Esperando 5 segundos antes del siguiente test...\n")
            time.sleep(5)

    # Si llegamos aqu√≠, ning√∫n modelo funcion√≥
    print("\n" + "=" * 70)
    print("üòû NING√öN MODELO PUDO RESOLVER EL PROBLEMA")
    print("=" * 70)
    print("\nüìù Opciones alternativas:")
    print("   1. Instalar Ollama y usar modelos locales m√°s potentes")
    print("   2. Usar API de OpenAI (GPT-3.5/GPT-4)")
    print("   3. Implementar extractor basado en reglas (sin IA)")
    print("   4. Simplificar manualmente el problema")
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Test cancelado por el usuario")
    except Exception as e:
        logger.error(f"\n‚ùå Error fatal: {e}")
        sys.exit(1)
