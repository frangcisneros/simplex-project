# ğŸ“– GuÃ­a Completa: Sistema NLP para Simplex

> **Resuelve problemas de optimizaciÃ³n lineal escribiendo en espaÃ±ol**

---

## ğŸ¯ Â¿QuÃ© es este sistema?

Este sistema te permite resolver problemas de **programaciÃ³n lineal** escribiÃ©ndolos en **lenguaje natural** (espaÃ±ol). En vez de escribir matrices y vectores manualmente, describes tu problema en palabras normales y el sistema automÃ¡ticamente:

1. âœ… Entiende quÃ© quieres maximizar o minimizar
2. âœ… Identifica las restricciones y lÃ­mites
3. âœ… Extrae los coeficientes numÃ©ricos
4. âœ… Construye el modelo matemÃ¡tico
5. âœ… Lo resuelve con el algoritmo Simplex

---

## ğŸš€ InstalaciÃ³n RÃ¡pida

### 1. Instalar Ollama (recomendado)

**Ollama** es una herramienta gratuita que ejecuta modelos de lenguaje localmente.

```bash
# Descargar e instalar desde: https://ollama.ai
# Luego instalar un modelo (recomendado: Llama 3.1)
ollama pull llama3.1:8b
```

### 2. Instalar dependencias Python

```bash
pip install -r requirements.txt
```

**Dependencias principales:**

- `requests` - Para comunicarse con Ollama
- `numpy` - Para cÃ¡lculos numÃ©ricos
- `scipy` (opcional) - Solvers adicionales

---

## ğŸ“ Uso BÃ¡sico

El script ahora **detecta automÃ¡ticamente** el formato del archivo, por lo que no necesitas especificar `--nlp` o `--classic`.

### OpciÃ³n 1: Desde archivo (detecciÃ³n automÃ¡tica)

```bash
# El sistema detecta automÃ¡ticamente si es lenguaje natural o formato clÃ¡sico
python nlp_simplex.py ejemplos/nlp/problema_complejo.txt
python nlp_simplex.py ejemplos/maximizar_basico.txt
```

### OpciÃ³n 2: Texto directo en lÃ­nea de comando

```bash
python nlp_simplex.py --text "Maximizar 3x + 2y sujeto a x + y <= 4"
```

### OpciÃ³n 3: Modo NLP explÃ­cito

```bash
# Forzar modo NLP (Ãºtil si el archivo no se detecta automÃ¡ticamente)
python nlp_simplex.py --nlp --file mi_problema.txt
```

### OpciÃ³n 4: Modo clÃ¡sico explÃ­cito

```bash
# Forzar modo clÃ¡sico (formato MAXIMIZE/MINIMIZE)
python nlp_simplex.py --classic archivo.txt
```

**Â¿CÃ³mo detecta el formato?**

- âœ… Si la primera lÃ­nea es `MAXIMIZE` o `MINIMIZE` â†’ Formato clÃ¡sico
- âœ… Si el archivo estÃ¡ en carpeta `nlp/` â†’ Lenguaje natural
- âœ… Si la primera lÃ­nea es larga (>50 caracteres) â†’ Lenguaje natural
- âœ… Por defecto â†’ Lenguaje natural

---

## ğŸ’¡ Ejemplos de Problemas

### Ejemplo 1: Problema Simple

**Entrada:**

```
Una empresa fabrica mesas y sillas. Cada mesa genera $50 de ganancia
y cada silla $30. Hay 100 horas de carpinterÃ­a disponibles.
Cada mesa requiere 4 horas y cada silla 2 horas.
Maximizar la ganancia.
```

**El sistema extrae automÃ¡ticamente:**

- Variables: x1 (mesas), x2 (sillas)
- FunciÃ³n objetivo: Maximizar 50x1 + 30x2
- RestricciÃ³n: 4x1 + 2x2 â‰¤ 100

**SoluciÃ³n:**

```
x1 = 25.0 (mesas)
x2 = 0.0 (sillas)
Ganancia mÃ¡xima = $1,250
```

### Ejemplo 2: Problema Multi-InstalaciÃ³n

**Entrada:**

```
Una empresa tiene 2 plantas. Planta 1 puede producir max 500 unidades,
Planta 2 max 700 unidades. Producen 3 productos: A, B, C con ganancias
de $10, $15, $20 por unidad respectivamente (igual en ambas plantas).
Hay demanda mÃ¡xima: producto A 300 unidades, B 400 unidades, C 600 unidades.
Maximizar ganancia.
```

**El sistema identifica:**

- Variables: x11, x12, x13 (planta 1), x21, x22, x23 (planta 2)
- Restricciones de capacidad por planta
- Restricciones de demanda por producto

### Ejemplo 3: Problema de Mezclas

**Entrada:**

```
Una refinerÃ­a tiene 1000 barriles de petrÃ³leo tipo 1 y 1500 de tipo 2.
Puede venderlos directamente a $40 y $35 por barril, o mezclarlos en
gasolina premium (70% tipo1 + 30% tipo2) que se vende a $50 por barril.
Maximizar ingresos.
```

**El sistema reconoce:**

- Variables: x1 (venta tipo1), x2 (venta tipo2), x3 (mezcla)
- Restricciones de disponibilidad con proporciones

---

## ğŸ§  CÃ³mo Funciona: Arquitectura

### Componentes Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. PROCESADOR NLP (OllamaNLPProcessor)                 â”‚
â”‚     â€¢ Lee el texto en espaÃ±ol                           â”‚
â”‚     â€¢ Usa modelo de lenguaje (Llama, Mistral, etc.)     â”‚
â”‚     â€¢ Extrae variables, restricciones y coeficientes    â”‚
â”‚     â€¢ Genera JSON estructurado                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. GENERADOR DE MODELO (SimplexModelGenerator)         â”‚
â”‚     â€¢ Valida el JSON extraÃ­do                           â”‚
â”‚     â€¢ Convierte a formato matemÃ¡tico (c, A, b)          â”‚
â”‚     â€¢ Verifica consistencia de dimensiones              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. SOLVER (SimplexSolver)                              â”‚
â”‚     â€¢ Resuelve el problema de optimizaciÃ³n              â”‚
â”‚     â€¢ Aplica el algoritmo Simplex                       â”‚
â”‚     â€¢ Devuelve soluciÃ³n Ã³ptima                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Estructura del CÃ³digo

```
src/
â”œâ”€â”€ nlp/                          # Sistema NLP
â”‚   â”œâ”€â”€ __init__.py              # Exporta clases pÃºblicas
â”‚   â”œâ”€â”€ interfaces.py            # Contratos de componentes
â”‚   â”œâ”€â”€ config.py                # â­ ConfiguraciÃ³n y prompts
â”‚   â”œâ”€â”€ ollama_processor.py     # Procesador con Ollama
â”‚   â”œâ”€â”€ processor.py             # Procesador con Transformers
â”‚   â”œâ”€â”€ model_generator.py       # Generadores de modelos
â”‚   â”œâ”€â”€ connector.py             # Orquestador del sistema
â”‚   â””â”€â”€ complexity_analyzer.py   # SelecciÃ³n automÃ¡tica de modelos
â”œâ”€â”€ solver.py                     # Algoritmo Simplex
â””â”€â”€ ...
```

---

## ğŸ¨ Mejora: Few-Shot Learning

### Â¿QuÃ© es Few-Shot Learning?

En lugar de entrenar el modelo desde cero, el sistema incluye **3 ejemplos concretos** en el prompt que enseÃ±an al modelo cÃ³mo extraer informaciÃ³n de diferentes tipos de problemas.

### Ejemplos Incluidos en el Prompt

El sistema muestra al modelo estos ejemplos antes de procesar tu problema:

1. **Ejemplo Simple** - Problema bÃ¡sico con 1 instalaciÃ³n
2. **Ejemplo Multi-InstalaciÃ³n** - Problema complejo con mÃºltiples plantas
3. **Ejemplo de Mezclas** - Problema con materias primas que se combinan

### Beneficios

- âœ… **No requiere re-entrenar** el modelo
- âœ… **Mejor precisiÃ³n** en problemas complejos
- âœ… **Funciona con cualquier modelo** (Mistral, Llama, Qwen)
- âœ… **FÃ¡cil de extender** - solo agregar mÃ¡s ejemplos

### UbicaciÃ³n del CÃ³digo

Los ejemplos estÃ¡n en: `src/nlp/config.py` â†’ `PromptTemplates.OPTIMIZATION_EXTRACTION_PROMPT`

---

## ğŸ¤– Modelos Disponibles

### ConfiguraciÃ³n Actual

Los modelos estÃ¡n configurados en `src/nlp/config.py`:

```python
class NLPModelType(Enum):
    MISTRAL_7B = "mistral:7b"      # Modelo versÃ¡til
    LLAMA3_1_8B = "llama3.1:8b"    # â­ RECOMENDADO - Mejor razonamiento
    QWEN2_5_14B = "qwen2.5:14b"    # Especializado en matemÃ¡ticas
    LLAMA3_2_3B = "llama3.2:3b"    # Ligero pero capaz
```

### Modelo Predeterminado

```python
DEFAULT_MODEL = NLPModelType.LLAMA3_1_8B  # El mejor para problemas complejos
```

### ComparaciÃ³n de Modelos

| Modelo              | TamaÃ±o | PrecisiÃ³n  | Velocidad  | Uso Recomendado         |
| ------------------- | ------ | ---------- | ---------- | ----------------------- |
| **Llama 3.1 8B** â­ | 4.7GB  | â­â­â­â­â­ | Media      | **Problemas complejos** |
| Mistral 7B          | 4.1GB  | â­â­â­â­   | RÃ¡pida     | Problemas generales     |
| Qwen 2.5 14B        | 9GB    | â­â­â­â­â­ | Lenta      | MatemÃ¡ticas avanzadas   |
| Llama 3.2 3B        | 2GB    | â­â­â­     | Muy rÃ¡pida | Problemas simples       |

### Instalar Modelos en Ollama

```bash
# Modelo recomendado
ollama pull llama3.1:8b

# Otros modelos
ollama pull mistral:7b
ollama pull qwen2.5:14b
ollama pull llama3.2:3b
```

### Cambiar de Modelo

Edita `src/nlp/config.py`:

```python
DEFAULT_MODEL = NLPModelType.MISTRAL_7B  # Cambiar aquÃ­
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### ParÃ¡metros del Modelo

UbicaciÃ³n: `src/nlp/config.py` â†’ `ModelConfig.DEFAULT_CONFIGS`

```python
DEFAULT_CONFIGS = {
    NLPModelType.LLAMA3_1_8B: {
        "temperature": 0.0,      # DeterminÃ­stico (0.0) vs Creativo (1.0)
        "max_tokens": 1536,      # Longitud mÃ¡xima de respuesta
        "top_p": 0.9,            # Nucleus sampling
    }
}
```

**ParÃ¡metros Explicados:**

- `temperature`: 0.0 = respuestas determinÃ­sticas (ideal para JSON)
- `max_tokens`: Espacio para problemas complejos (mÃ¡s = mejor)
- `top_p`: Control de creatividad (0.9 = balance)

### Ajustar el Prompt

El prompt estÃ¡ en `src/nlp/config.py` â†’ `PromptTemplates.OPTIMIZATION_EXTRACTION_PROMPT`

**Para agregar un nuevo ejemplo:**

1. Abre `src/nlp/config.py`
2. Busca la secciÃ³n "EJEMPLOS DE APRENDIZAJE (Few-Shot)"
3. Agrega un nuevo ejemplo siguiendo el formato:

```python
EJEMPLO 4 - Tu Nuevo Tipo de Problema:
ENUNCIADO: "DescripciÃ³n del problema..."

RESPUESTA CORRECTA:
{{
  "objective_type": "maximize",
  "variable_names": ["x1", "x2"],
  "objective_coefficients": [10, 20],
  "constraints": [
    {{"coefficients": [1, 2], "operator": "<=", "rhs": 100}}
  ],
  "non_negativity": true
}}
```

---

## ğŸ“‚ Archivos de Ejemplo

### UbicaciÃ³n: `ejemplos/nlp/`

```
ejemplos/nlp/
â”œâ”€â”€ problema_simple.txt         # Problema bÃ¡sico de 2 variables
â”œâ”€â”€ problema_complejo.txt       # Problema de 3 plantas (9 variables)
â””â”€â”€ problema_compolejo2.txt     # Otro problema complejo
```

### Crear Tu Propio Ejemplo

1. Crea un archivo `.txt` en `ejemplos/nlp/`
2. Escribe tu problema en espaÃ±ol natural
3. Ejecuta: `python nlp_simplex.py ejemplos/nlp/tu_archivo.txt`

**Consejos para escribir problemas:**

âœ… **SÃ© especÃ­fico con los nÃºmeros**

- Bueno: "Cada mesa requiere 4 horas"
- Malo: "Cada mesa requiere varias horas"

âœ… **Menciona claramente el objetivo**

- Bueno: "Maximizar la ganancia total"
- Malo: "Queremos ganar mÃ¡s"

âœ… **Define todas las restricciones**

- Incluye capacidades, demandas, disponibilidad
- Usa palabras como: "mÃ¡ximo", "lÃ­mite", "disponible"

---

## ğŸ› SoluciÃ³n de Problemas

### Problema: "No se pudo conectar con Ollama"

**SoluciÃ³n:**

```bash
# 1. Verificar que Ollama estÃ¡ corriendo
ollama list

# 2. Si no estÃ¡ corriendo, iniciarlo
ollama serve

# 3. Verificar que el modelo estÃ¡ instalado
ollama pull llama3.1:8b
```

### Problema: "El modelo no genera JSON vÃ¡lido"

**Causas comunes:**

- Temperature muy alta (debe ser 0.0)
- Problema ambiguo o mal descrito
- Modelo no adecuado para el problema

**SoluciÃ³n:**

```bash
# 1. Verificar configuraciÃ³n en src/nlp/config.py
temperature = 0.0

# 2. Probar con modelo mÃ¡s potente
ollama pull qwen2.5:14b

# 3. Hacer el problema mÃ¡s explÃ­cito
```

### Problema: "Dimensiones inconsistentes"

**Causa:** El modelo identificÃ³ mal el nÃºmero de variables

**SoluciÃ³n:**

- SÃ© mÃ¡s explÃ­cito en la descripciÃ³n
- Enumera claramente todas las variables
- Revisa los ejemplos few-shot en el prompt

### Problema: "Tiempo de espera agotado"

**Causa:** El modelo es muy lento o el problema muy complejo

**SoluciÃ³n:**

```python
# En src/nlp/config.py
MAX_PROCESSING_TIME = 120.0  # Aumentar tiempo (default: 60)
```

---

## ğŸ“Š Formato de Salida

### JSON Intermedio (Debug)

El sistema genera un JSON estructurado antes de resolver:

```json
{
	"objective_type": "maximize",
	"variable_names": ["x1", "x2", "x3"],
	"objective_coefficients": [420, 360, 300],
	"constraints": [
		{
			"coefficients": [1, 1, 1],
			"operator": "<=",
			"rhs": 750
		}
	],
	"non_negativity": true
}
```

### SoluciÃ³n Final

```
=== SOLUCIÃ“N Ã“PTIMA ===
x1 = 250.0
x2 = 300.0
x3 = 200.0

Valor Ã³ptimo: 242,000.0
```

---

## ğŸ“ Casos de Uso

### 1. Problemas de ProducciÃ³n

```
Una fÃ¡brica produce widgets y gadgets...
```

**El sistema identifica:**

- Variables de producciÃ³n por producto
- Restricciones de recursos (materias primas, tiempo, etc.)
- FunciÃ³n objetivo de maximizaciÃ³n de ganancia

### 2. Problemas de DistribuciÃ³n

```
Una empresa tiene 3 almacenes y 5 tiendas...
```

**El sistema reconoce:**

- Variables indexadas (almacÃ©n Ã— tienda)
- Restricciones de capacidad y demanda
- MinimizaciÃ³n de costos de transporte

### 3. Problemas de Mezclas

```
Una planta quÃ­mica mezcla materias primas...
```

**El sistema entiende:**

- Variables de venta directa vs mezcla
- Proporciones en las mezclas (70%, 30%, etc.)
- Restricciones de disponibilidad

### 4. Problemas de AsignaciÃ³n

```
Asignar empleados a tareas minimizando tiempo...
```

**El sistema extrae:**

- Matriz de asignaciÃ³n (empleado Ã— tarea)
- Restricciones de capacidad por empleado
- MinimizaciÃ³n de tiempo/costo total

---

## ğŸ“ˆ Rendimiento y Limitaciones

### Casos que Funciona Bien âœ…

- Problemas con hasta 50 variables
- Hasta 100 restricciones
- Problemas con estructura clara
- Coeficientes numÃ©ricos explÃ­citos

### Casos DifÃ­ciles âš ï¸

- NÃºmeros no explÃ­citos ("varios", "muchos")
- Restricciones implÃ­citas no mencionadas
- Problemas con lÃ³gica compleja (if-then-else)
- Objetivos mÃºltiples (requiere reformulaciÃ³n)

### Tiempos Aproximados

| Modelo       | Problema Simple | Problema Complejo |
| ------------ | --------------- | ----------------- |
| Llama 3.2 3B | 5-10 seg        | 15-30 seg         |
| Llama 3.1 8B | 10-20 seg       | 30-60 seg         |
| Qwen 2.5 14B | 20-40 seg       | 60-120 seg        |

_En CPU sin GPU. Con GPU serÃ­a 3-5x mÃ¡s rÃ¡pido._

---

## ğŸ”„ Workflow Completo

```
1. ESCRIBES el problema en espaÃ±ol
   â†“
2. OLLAMA procesa el texto con el modelo de lenguaje
   â†“
3. SISTEMA NLP extrae variables, restricciones, coeficientes
   â†“
4. VALIDADOR verifica que el JSON sea correcto
   â†“
5. GENERADOR convierte a formato matemÃ¡tico (c, A, b)
   â†“
6. SIMPLEX resuelve el problema de optimizaciÃ³n
   â†“
7. OBTIENES la soluciÃ³n Ã³ptima
```

---

## ğŸ’» Comandos Ãštiles

### Uso bÃ¡sico (detecciÃ³n automÃ¡tica)

```bash
# El sistema detecta el formato automÃ¡ticamente
python nlp_simplex.py ejemplos/nlp/problema_complejo.txt
```

### Uso con texto directo

```bash
python nlp_simplex.py --text "Maximizar 3x + 2y sujeto a x + y <= 4"
```

### Ver modelos instalados en Ollama

```bash
ollama list
```

### Probar un modelo directamente

```bash
ollama run llama3.1:8b
```

### Ejecutar con modo verbose (mÃ¡s informaciÃ³n)

```bash
python nlp_simplex.py --verbose ejemplos/nlp/problema_complejo.txt
```

### Forzar modo NLP o clÃ¡sico

```bash
# Forzar modo NLP
python nlp_simplex.py --nlp --file mi_archivo.txt

# Forzar modo clÃ¡sico
python nlp_simplex.py --classic archivo.txt
```

---

## ğŸ¤ Contribuir

### Agregar soporte para un nuevo modelo

1. Agregar a `NLPModelType` en `src/nlp/config.py`
2. Agregar configuraciÃ³n en `ModelConfig.DEFAULT_CONFIGS`
3. Probar con varios problemas

### Mejorar el prompt

1. Editar `PromptTemplates.OPTIMIZATION_EXTRACTION_PROMPT`
2. Agregar mÃ¡s ejemplos few-shot
3. Mejorar instrucciones de anÃ¡lisis

### Reportar problemas

- Incluir el texto del problema
- Incluir el modelo usado
- Incluir el error completo

---

## ğŸ“š Referencias

### DocumentaciÃ³n TÃ©cnica

- **Ollama**: https://ollama.ai
- **Few-Shot Learning**: TÃ©cnica de aprendizaje con pocos ejemplos
- **Simplex**: Algoritmo de optimizaciÃ³n lineal

### Archivos Clave

- `src/nlp/config.py` - ConfiguraciÃ³n, modelos, prompts
- `src/nlp/ollama_processor.py` - Procesador con Ollama
- `src/nlp/connector.py` - Orquestador del sistema
- `nlp_simplex.py` - Punto de entrada principal

---

## ğŸ¯ Resumen de Uso RÃ¡pido

```bash
# 1. Instalar Ollama
# Descargar desde https://ollama.ai

# 2. Instalar modelo
ollama pull llama3.1:8b

# 3. Instalar dependencias Python
pip install -r requirements.txt

# 4. Ejecutar con tu problema
python nlp_simplex.py ejemplos/nlp/problema_complejo.txt

# 5. Â¡Listo! ObtendrÃ¡s la soluciÃ³n Ã³ptima
```

---

## â­ CaracterÃ­sticas Destacadas

- ğŸ§  **Inteligencia Artificial** - Usa modelos de lenguaje avanzados
- ğŸ¯ **Few-Shot Learning** - Aprende de ejemplos sin re-entrenar
- ğŸš€ **FÃ¡cil de usar** - Solo escribe en espaÃ±ol
- ğŸ”§ **Configurable** - MÃºltiples modelos disponibles
- ğŸ“ˆ **Escalable** - Hasta 50 variables y 100 restricciones
- ğŸ’° **Gratis** - Usa Ollama localmente sin costo
- ğŸ”’ **Privado** - Todo se ejecuta en tu computadora

---

**Ãšltima actualizaciÃ³n:** Octubre 7, 2025  
**VersiÃ³n:** 2.0 con Few-Shot Learning
