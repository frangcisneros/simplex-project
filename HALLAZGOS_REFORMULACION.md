# Hallazgos sobre ReformulaciÃ³n de Problemas para NLP

## Fecha: 2024

## Experimento: ReformulaciÃ³n de Problemas Complejos

### HipÃ³tesis Inicial

Reescribir problemas con estructura explÃ­cita (listas numeradas, secciones claras, conteo de variables explÃ­cito) ayudarÃ­a al modelo LLM a extraer mejor las variables y restricciones.

### Resultados del Experimento

#### âŒ VersiÃ³n Reformulada "Muy Verbosa" (Intento 1)

**Contenido**: Secciones en MAYÃšSCULAS, nota explÃ­cita "9 variables de decisiÃ³n (3 plantas Ã— 3 tamaÃ±os)", lista completa de variables, explicaciones detalladas.

**Resultado**:

- Processing time: 169.4s (vs tÃ­pico 65-85s)
- Error: "No valid JSON found in model response"
- El modelo se saturÃ³ con demasiada informaciÃ³n explÃ­cita

#### âš ï¸ VersiÃ³n Reformulada "Compacta" (Intento 2)

**Contenido**: Formato comprimido con estructura explÃ­cita pero menos verbose:

```
PROBLEMA: CompaÃ±Ã­a con 3 plantas...
ESTRUCTURA: 3 plantas Ã— 3 tamaÃ±os = 9 variables
Variables: x11, x12, x13, x21, x22, x23, x31, x32, x33
GANANCIAS POR UNIDAD: ...
```

**Resultados variables**:

- Intento 1: "No valid JSON found"
- Intento 2: Extrajo solo 6 coeficientes en restricciones (debÃ­an ser 9)
- Intento 3: Extrajo solo 3 variables (debÃ­an ser 9)

#### âœ… VersiÃ³n Original (Lenguaje Natural)

**Contenido**: Texto narrativo descriptivo sin estructura explÃ­cita:

```
"Cierta compaÃ±Ã­a tiene tres plantas con un exceso en su capacidad de producciÃ³n.
Por fortuna, la corporaciÃ³n tiene un nuevo producto listo para producciÃ³n y las
tres plantas pueden fabricarlo..."
```

**Resultado**:

- âœ… Extrajo 9 variables correctamente
- âœ… GenerÃ³ JSON vÃ¡lido consistentemente
- âœ… ResolviÃ³ el problema (ganancia Ã³ptima: $420,000)
- âš ï¸ Solo generÃ³ 5 de 12 restricciones esperadas, pero suficientes para resolver

### ConclusiÃ³n

**LA VERSIÃ“N ORIGINAL FUNCIONA MEJOR QUE LAS REFORMULADAS**

#### Por quÃ© las reformulaciones fallaron:

1. **Exceso de estructura explÃ­cita** confunde al modelo

   - El modelo estÃ¡ entrenado con texto natural, no con formato esquemÃ¡tico
   - Las notaciones "3 Ã— 3 = 9" pueden ser interpretadas literalmente en vez de conceptualmente

2. **PÃ©rdida de contexto semÃ¡ntico**

   - Al comprimir, se perdieron palabras clave que el modelo usa para inferir relaciones
   - Ejemplo: "cada planta puede producir" vs "Variables: x11, x12, x13"

3. **Compromiso formato vs contexto**
   - Texto narrativo da pistas contextuales ("tres plantas", "tres tamaÃ±os", "cada")
   - Formato esquemÃ¡tico elimina redundancia pero tambiÃ©n elimina seÃ±ales importantes

### Lecciones Aprendidas

#### âœ… QuÃ© SÃ funciona:

- **Lenguaje natural descriptivo** con redundancia estratÃ©gica
- **RepeticiÃ³n de conceptos clave** ("tres plantas", "tres tamaÃ±os")
- **Conectores y contexto** ("cada planta puede...", "sin importar el tamaÃ±o...")
- **Prompts mejorados** con ejemplos few-shot explÃ­citos y validaciÃ³n

#### âŒ QuÃ© NO funciona:

- Formatos esquemÃ¡ticos tipo lista
- Exceso de notaciÃ³n matemÃ¡tica explÃ­cita
- CompresiÃ³n agresiva del lenguaje
- Secciones en MAYÃšSCULAS con estructura rÃ­gida

### RecomendaciÃ³n Final

**NO reformular los problemas**. En su lugar:

1. **Mejorar los prompts** con:

   - MÃ¡s ejemplos few-shot (5+ ejemplos como el problema target)
   - ValidaciÃ³n explÃ­cita ("verifica que len(coefficients) == len(variables)")
   - Ã‰nfasis en patrones crÃ­ticos (emoji ðŸš¨, negritas en los ejemplos)

2. **Mantener texto natural** con:

   - Descripciones narrativas
   - Redundancia estratÃ©gica de conceptos
   - Conectores contextuales

3. **ValidaciÃ³n post-extracciÃ³n** que:
   - Detecta estructura esperada (ProblemStructureDetector)
   - Compara extraÃ­do vs esperado
   - Genera warnings claros
   - Permite continuar con soluciÃ³n subÃ³ptima

### MÃ©tricas Finales

| VersiÃ³n              | Variables ExtraÃ­das | Restricciones     | SoluciÃ³n     | Tiempo     |
| -------------------- | ------------------- | ----------------- | ------------ | ---------- |
| Reformulada Verbosa  | N/A (JSON invÃ¡lido) | N/A               | âŒ FallÃ³     | 169.4s     |
| Reformulada Compacta | 3-9 (inconsistente) | 2-4 (incompletas) | âš ï¸ Variable  | 83-129s    |
| **Original**         | **9/9 âœ…**          | **5/12**          | **âœ… $420k** | **148.7s** |

### Estado Actual del Sistema

âœ… **Sistema funcional** con:

- ProblemStructureDetector (100% precisiÃ³n)
- Prompts mejorados con 5 ejemplos few-shot
- ValidaciÃ³n con warnings informativos
- Soporte multi-modelo (Llama 3.1:8b recomendado)

âš ï¸ **LimitaciÃ³n aceptada**:

- Modelos locales 7-8B extraen 67-93% de restricciones
- Suficiente para problemas simples/medianos
- Para producciÃ³n: usar GPT-4/Claude vÃ­a API

ðŸ“ **Trabajo futuro**:

- IntegraciÃ³n con API de OpenAI/Anthropic
- Chunking para problemas muy grandes (>12 restricciones)
- Post-procesamiento para inferir restricciones faltantes
